# PVP4Real Unified Configuration File
# This configuration file contains all command-line arguments for the three main scripts:
# - stretch3.hitl.py: Human-In-The-Loop training
# - stretch3.deploy.py: Deployment/inference only
# - pvp.hitl.py: Original PVP HITL training

# =============================================================================
# Common Parameters (shared across all scripts)
# =============================================================================
common:
  # Control frequency in Hz (wall-clock rate)
  hz: 5.0
  
  # Maximum linear velocity in m/s (maps to action=+1)
  max_lin: 0.4
  
  # Maximum angular velocity in rad/s (maps to action=+1)
  max_ang: 1.2
  
  # Observation processing
  depth_max_m: 5.0          # Depth clip maximum in meters, mapped to 255
  stack_n: 5                # Number of frames to stack (paper setting)
  resize:                   # Resize dimensions [H, W] for RGB-D
    height: 84
    width: 84
  
  # Random seed for reproducibility
  seed: 0
  
  # PyTorch device (auto, cuda, cpu)
  device: "auto"


# =============================================================================
# ROS2 Topic Configuration
# =============================================================================
ros2_topics:
  # RGB image topic
  rgb: "/camera/camera/color/image_raw"
  
  # Aligned depth image topic
  depth: "/camera/camera/aligned_depth_to_color/image_raw"
  
  # Teleop state (True = human takeover)
  is_teleop: "/stretch/is_teleop"
  
  # Human teleop velocity command
  cmd_vel_teleop: "/stretch/cmd_vel_teleop"
  
  # Final velocity command (published)
  cmd_vel: "/stretch/cmd_vel"


# =============================================================================
# Training Parameters (stretch3.hitl.py)
# =============================================================================
training:
  # Model checkpoint and log directory
  model_dir: "/workspace/pvp4real/models/stretch3_hitl"
  
  ### Resume from checkpoint ###
  # Enable/disable resume from checkpoint
  is_resume_training: false
  # Directory path containing checkpoint files (if enabled)
  # e.g., "/workspace/pvp4real/models/stretch3_hitl/pvp4real_stretch3_step100.zip"                    
  resume_from: null                                            

  
  # Total environment steps (wall-clock ticks) to train
  # total_steps: 50000
  total_steps: 500

  # Steps before training starts (initial data collection)
  # learning_starts: 500
  learning_starts: 50
  
  # Replay buffer size
  buffer_size: 10000
  
  # Batch size for TD3/PVP updates
  batch_size: 128
  
  # Checkpoint frequency (save every N steps)
  # save_every: 2500
  save_every: 100
  
  # SB3 logging interval
  log_interval: 10
  
  # PVP-specific hyperparameters
  pvp:
    # Q-value bound for PVP loss
    q_value_bound: 1.0
    
    # Behavior cloning loss weight
    bc_loss_weight: 1.0
    
    # Enable human proxy value loss
    with_human_proxy_value_loss: true
    
    # Enable agent proxy value loss
    with_agent_proxy_value_loss: true
    
    # Use only BC loss (disable RL)
    only_bc_loss: false
    
    # Add BC loss to training
    add_bc_loss: true
    
    # TD3 hyperparameters
    gamma: 0.99
    tau: 0.05
    learning_rate: 0.0001
    train_freq: 1
    gradient_steps: 1


# =============================================================================
# Deployment Parameters (stretch3.deploy.py)
# =============================================================================
deployment:
  # Path to the trained model (.zip file)
  model_path: "/pvp4real/models/stretch3_hitl/pvp4real_stretch3_final.zip"


# =============================================================================
# Original PVP HITL Parameters (pvp.hitl.py)
# =============================================================================
pvp_hitl:
  # Model save path
  model_save_path: "pvp4real_stretch3_hitl_final"
  
  # Training configuration (similar to training section above)
  buffer_size: 200000
  learning_starts: 500
  batch_size: 1024
  total_steps: 200000
  
  # TD3 parameters
  train_freq: 1
  gradient_steps: 1
  gamma: 0.99
  tau: 0.05
  learning_rate: 0.0001
  
  # PVP parameters
  q_value_bound: 1.0
  add_bc_loss: true
  with_human_proxy_value_loss: true
  with_agent_proxy_value_loss: true
  verbose: 1


# =============================================================================
# Hardware Limits (Safety)
# =============================================================================
hardware:
  # Emergency stop thresholds
  emergency_stop:
    enabled: true
    min_obstacle_distance: 0.3  # meters
  
  # Velocity limits (absolute maximum, for safety)
  velocity_limits:
    max_linear: 0.5     # m/s
    max_angular: 0.5    # rad/s
    min_linear: -0.3    # m/s (reverse)


# =============================================================================
# Logging and Debugging
# =============================================================================
logging:
  # Log level (DEBUG, INFO, WARNING, ERROR)
  level: "INFO"
  
  # Enable verbose output
  verbose: true
  
  # Save trajectories to disk
  save_trajectories: true
  trajectory_dir: "/pvp4real/trajectories"
  
  # TensorBoard logging
  tensorboard:
    enabled: true
    log_dir: "/pvp4real/logs"


# =============================================================================
# Experimental Features
# =============================================================================
experimental:
  # Use image augmentation during training
  use_augmentation: false
  
  # Enable domain randomization
  domain_randomization: false
  
  # Record videos during training
  record_video: false
  video_dir: "/pvp4real/videos"
  video_freq: 1000  # record every N steps
