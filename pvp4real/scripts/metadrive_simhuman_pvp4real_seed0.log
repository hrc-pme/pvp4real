/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.
See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
[38;20m[INFO] Environment: HumanInTheLoopEnv[0m
[38;20m[INFO] MetaDrive version: 0.4.3[0m
[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()][0m
[38;20m[INFO] Render Mode: none[0m
[38;20m[INFO] Horizon (Max steps per agent): 1500[0m
Using cpu device
Wrapping the env with a `Monitor` wrapper
[38;20m[INFO] Assets version: 0.4.3[0m
[38;20m[INFO] Known Pipes: glxGraphicsPipe[0m
[38;20m[INFO] Start Scenario Index: 100, Num Scenarios : 50[0m
INFO:/workspace/pvp4real/pvp/sb3/common/monitor.py:In Monitor, we auto detect the record keys: ('overtake_vehicle_num', 'velocity', 'steering', 'acceleration', 'step_energy', 'episode_energy', 'policy', 'navigation_command', 'navigation_forward', 'navigation_left', 'navigation_right', 'action', 'raw_action', 'crash_vehicle', 'crash_object', 'crash_building', 'crash_human', 'crash_sidewalk', 'out_of_road', 'arrive_dest', 'max_step', 'env_seed', 'crash', 'step_reward', 'route_completion', 'cost', 'total_cost', 'episode_reward', 'episode_length', 'takeover_start', 'takeover', 'takeover_cost', 'total_takeover_cost', 'native_cost', 'episode_native_cost', 'total_takeover_count', 'ep_overtake_vehicle_num', 'ep_velocity', 'ep_steering', 'ep_acceleration', 'ep_step_energy', 'ep_episode_energy', 'ep_policy', 'ep_navigation_command', 'ep_navigation_forward', 'ep_navigation_left', 'ep_navigation_right', 'ep_action', 'ep_raw_action', 'ep_crash_vehicle', 'ep_crash_object', 'ep_crash_building', 'ep_crash_human', 'ep_crash_sidewalk', 'ep_out_of_road', 'ep_arrive_dest', 'ep_max_step', 'ep_env_seed', 'ep_crash', 'ep_step_reward', 'ep_route_completion', 'ep_cost', 'ep_total_cost', 'ep_episode_reward', 'ep_episode_length', 'ep_takeover_start', 'ep_takeover', 'ep_takeover_cost', 'ep_total_takeover_cost', 'ep_native_cost', 'ep_episode_native_cost', 'ep_total_takeover_count')
Wrapping the env in a DummyVecEnv.
Loading checkpoint from /workspace/pvp4real/pvp/experiments/metadrive/egpo/metadrive_pvp_20m_steps!
/workspace/pvp4real/pvp/sb3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.
  warnings.warn(
/workspace/pvp4real/pvp/sb3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.
  warnings.warn(
/workspace/pvp4real/pvp/sb3/common/save_util.py:440: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  th_object = th.load(file_content, map_location=device)
Model is loaded from /workspace/pvp4real/pvp/experiments/metadrive/egpo/metadrive_pvp_20m_steps!
Trial name is set to:  metadrive_simhuman_pvp4real_freelevel0.95_2026-02-01_14-22-06_4e7201ad
[WARNING] Please note that you are not using wandb right now!!!
We start logging training data into /home/zhenghao/pvp/runs/metadrive_simhuman_pvp4real_freelevel0.95/metadrive_simhuman_pvp4real_freelevel0.95_2026-02-01_14-22-06_4e7201ad
[38;20m[INFO] Environment: FakeHumanEnv[0m
[38;20m[INFO] MetaDrive version: 0.4.3[0m
[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector(), main_camera: MainCamera(1200, 900), dashboard: DashBoard()][0m
[38;20m[INFO] Render Mode: onscreen[0m
[38;20m[INFO] Horizon (Max steps per agent): 1500[0m
[38;20m[INFO] Assets version: 0.4.3[0m
Xlib:  extension "XFree86-DGA" missing on display ":0".
[38;20m[INFO] Known Pipes: glxGraphicsPipe[0m
[38;20m[INFO] Start Scenario Index: 100, Num Scenarios : 50[0m
INFO:/workspace/pvp4real/pvp/sb3/common/monitor.py:In Monitor, we auto detect the record keys: ('overtake_vehicle_num', 'velocity', 'steering', 'acceleration', 'step_energy', 'episode_energy', 'policy', 'navigation_command', 'navigation_forward', 'navigation_left', 'navigation_right', 'action', 'raw_action', 'crash_vehicle', 'crash_object', 'crash_building', 'crash_human', 'crash_sidewalk', 'out_of_road', 'arrive_dest', 'max_step', 'env_seed', 'crash', 'step_reward', 'route_completion', 'cost', 'total_cost', 'episode_reward', 'episode_length', 'takeover_start', 'takeover', 'takeover_cost', 'total_takeover_cost', 'native_cost', 'episode_native_cost', 'total_takeover_count', 'takeover_log_prob', 'ep_overtake_vehicle_num', 'ep_velocity', 'ep_steering', 'ep_acceleration', 'ep_step_energy', 'ep_episode_energy', 'ep_policy', 'ep_navigation_command', 'ep_navigation_forward', 'ep_navigation_left', 'ep_navigation_right', 'ep_action', 'ep_raw_action', 'ep_crash_vehicle', 'ep_crash_object', 'ep_crash_building', 'ep_crash_human', 'ep_crash_sidewalk', 'ep_out_of_road', 'ep_arrive_dest', 'ep_max_step', 'ep_env_seed', 'ep_crash', 'ep_step_reward', 'ep_route_completion', 'ep_cost', 'ep_total_cost', 'ep_episode_reward', 'ep_episode_length', 'ep_takeover_start', 'ep_takeover', 'ep_takeover_cost', 'ep_total_takeover_cost', 'ep_native_cost', 'ep_episode_native_cost', 'ep_total_takeover_count', 'ep_takeover_log_prob')
Fatal Python error: preconfig_init_utf8_mode: invalid PYTHONUTF8 environment variable value
Python runtime state: preinitializing

Fatal Python error: preconfig_init_utf8_mode: invalid PYTHONUTF8 environment variable value
Python runtime state: preinitializing

Traceback (most recent call last):
  File "/workspace/pvp4real/pvp/experiments/metadrive/train_pvp_metadrive_fakehuman.py", line 154, in <module>
    eval_env = SubprocVecEnv([_make_eval_env])
  File "/workspace/pvp4real/pvp/sb3/common/vec_env/subproc_vec_env.py", line 105, in __init__
    process.start()
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/lib/python3.10/multiprocessing/context.py", line 300, in _Popen
    return Popen(process_obj)
  File "/usr/lib/python3.10/multiprocessing/popen_forkserver.py", line 35, in __init__
    super().__init__(process_obj)
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/lib/python3.10/multiprocessing/popen_forkserver.py", line 51, in _launch
    self.sentinel, w = forkserver.connect_to_new_process(self._fds)
  File "/usr/lib/python3.10/multiprocessing/forkserver.py", line 88, in connect_to_new_process
    client.connect(self._forkserver_address)
ConnectionRefusedError: [Errno 111] Connection refused
